{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "import os\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "dirs = glob('../GNN_exp/msg_gnn/Msg*')\n",
    "# dirs = glob('exp/node_gnn/Node*')\n",
    "dirs.sort(key=os.path.abspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prob_gibbs', 'prob_hmc', 'J', 'b', 'seed_train', 'block_size', 'travel_time', 'time_gibbs', 'time_hmc', 'G', 'msg_node', 'idx_msg_edge', 'J_msg'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pickle.load(open('../data_christmas/test_II/graph_barbell_nn100_0000001.p', 'rb'))\n",
    "temp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4902, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['msg_node'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235396, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['idx_msg_edge'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4902, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['J_msg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.topology import get_msg_graph\n",
    "dirs = glob('../data_christmas/test_IV/*.p')\n",
    "dirs.sort(key=os.path.abspath)\n",
    "\n",
    "for ii, dr in enumerate(dirs):\n",
    "    graph = pickle.load(open(dr, 'rb'))\n",
    "\n",
    "    G = nx.from_numpy_array(graph['J'].todense())\n",
    "    msg_node, msg_adj = get_msg_graph(G)\n",
    "    msg_node, msg_adj = np.array(msg_node), np.array(msg_adj)\n",
    "    idx_msg_edge = np.transpose(np.nonzero(msg_adj))\n",
    "    J_msg = graph['J'].todense()[msg_node[:, 0], msg_node[:, 1]].reshape(-1, 1)\n",
    "\n",
    "    graph['msg_node'] = msg_node\n",
    "    graph['idx_msg_edge'] = idx_msg_edge\n",
    "    graph['J_msg'] = J_msg\n",
    "\n",
    "    with open(dr, 'wb') as f:\n",
    "        pickle.dump(graph, f)\n",
    "        del graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['J'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prob_gt', 'J', 'b', 'seed_train', 'G'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp0 = pickle.load(open('../data_christmas/train/graph_barbell_nn9_0000001.p', 'rb'))\n",
    "temp0.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp0['J'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "True\n",
      "True\n",
      "> <ipython-input-5-a43c0b00a065>(64)<module>()\n",
      "-> graph['msg_node'] = msg_node\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a43c0b00a065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msg_node'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msg_adj'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx_msg_edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a43c0b00a065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msg_node'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msg_adj'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx_msg_edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dirs = glob('../../Documents/train/*.p')\n",
    "dirs.sort(key=os.path.abspath)\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "from utils.topology import get_msg_graph\n",
    "\n",
    "idx_mat = np.random.permutation(len(dirs)).reshape(-1,10)\n",
    "\n",
    "for jj, idx_row in enumerate(idx_mat):\n",
    "    if jj % 10 == 0:\n",
    "        print(jj)\n",
    "        \n",
    "    graph = {}\n",
    "    batch = []\n",
    "    for ii in idx_row:\n",
    "        train_data = pickle.load(open(dirs[ii], 'rb'))\n",
    "        batch.append(train_data)\n",
    "    # ================================================\n",
    "    graph['prob_gt'] = np.concatenate([bch['prob_gt'] for bch in batch], axis=0)\n",
    "    graph['b'] = np.concatenate([bch['b'] for bch in batch], axis=0)\n",
    "    graph['J_msg'] = np.concatenate([bch['J_msg'] for bch in batch], axis=0)\n",
    "\n",
    "    n = graph['b'].shape[0]\n",
    "    graph['J'] = coo_matrix(np.zeros([n, n]))\n",
    "    \n",
    "    row = []\n",
    "    col = []\n",
    "    val = []\n",
    "    for ii, bch in enumerate(batch):\n",
    "        nv = bch['J'].shape[0]\n",
    "        row.append(bch['J'].row + nv * ii)\n",
    "        col.append(bch['J'].col + nv * ii)\n",
    "        val.append(bch['J'].data)\n",
    "\n",
    "    graph['J'].row = np.concatenate(row)\n",
    "    graph['J'].col = np.concatenate(col)\n",
    "    graph['J'].data = np.concatenate(val)\n",
    "        \n",
    "    graph['seed_train'] = 11111\n",
    "            \n",
    "    # msg_node2 = msg_node1 + len(msg_node1)\n",
    "    # msg_adj2 = msg_adj1 + msg_adj1.shape[0]\n",
    "    # idx_msg_edge == np.vstack([idx_msg_edge1, msg_node1.shape[0] + idx_msg_edge2])\n",
    "\n",
    "    G = nx.from_scipy_sparse_matrix(graph['J'])\n",
    "    msg_node, msg_adj = get_msg_graph(G)\n",
    "    msg_node = np.array(msg_node)\n",
    "    msg_adj = np.array(msg_adj)\n",
    "    idx_msg_edge = np.transpose(np.nonzero(msg_adj))\n",
    "    \n",
    "    tp_msg_node = np.empty((0,2))\n",
    "    tp_idx_msg_edge = np.empty((0,2))\n",
    "    num_msg_node = 0\n",
    "    for bch in batch:\n",
    "        tp_idx_msg_edge = np.vstack((tp_idx_msg_edge, tp_msg_node.shape[0] + bch['idx_msg_edge']))\n",
    "        tp_msg_node = np.vstack((tp_msg_node, num_msg_node + bch['msg_node']))\n",
    "        num_msg_node = 1 + tp_msg_node.max()\n",
    "        \n",
    "    print((msg_node==tp_msg_node).all())\n",
    "    print((idx_msg_edge==tp_idx_msg_edge).all())\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    \n",
    "    graph['msg_node'] = msg_node\n",
    "    graph['msg_adj'] = idx_msg_edge\n",
    "    \n",
    "    graph['J'] = graph['J'].tolil()\n",
    "    temp = [graph['J'][msg_node[r, 0], msg_node[r, 1]] for r in range(msg_node.shape[0])]\n",
    "    graph['J'] = np.array(temp).reshape(-1,1)\n",
    "    \n",
    "\n",
    "#     file_name = os.path.join('../../Documents/', 'train', 'graph_nn9_{:07d}.p'.format(1+jj))\n",
    "#     with open(file_name, 'wb') as f:\n",
    "#         pickle.dump(graph, f)\n",
    "#         del graph\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(37):\n",
    "#     test_type = 'test_II'\n",
    "#     config_file = glob(dirs[idx] + '/*.yaml')[0]\n",
    "#     config = yaml.load(open(config_file, 'r'), Loader=yaml.FullLoader)\n",
    "#     config['exp_dir'] = dirs[idx]\n",
    "#     config['dataset']['data_path'] = '../data_christmas/'\n",
    "#     config['dataset']['split'] = test_type\n",
    "#     config['test']['test_model'] = dirs[idx] + '/model_snapshot_best.pth'\n",
    "#     config['test']['batch_size'] = 1\n",
    "#     cfg_path = dirs[idx] + '/config_test.yaml'\n",
    "#     with open(cfg_path, 'w') as ymlfile:\n",
    "#         yaml.dump(config, ymlfile, explicit_start=True)\n",
    "\n",
    "#     ! python3 run_exp_local.py -c {cfg_path} -t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(0, 7), \n",
    "                  columns=[\"bvl\", \"hidden_dim\", \"num_prop\", \"aggregate_type\", \"loss\", \"lr\", \"wd\"])\n",
    "test_type = 'test_II'\n",
    "bvl = []\n",
    "for ii, dr in enumerate(dirs):\n",
    "    train_files = glob(dr + '/*.p')\n",
    "    train_data = pickle.load(open(train_files[0], 'rb'))\n",
    "    \n",
    "    test_files = glob(dr + '/*' + test_type + '.csv')\n",
    "    q = pd.read_csv(test_files[0], sep='\\t', header=None).values.reshape(13,1000,2)\n",
    "    p = pd.read_csv(test_files[1], sep='\\t', header=None).values.reshape(13,1000,2)\n",
    "\n",
    "    config_file = glob(dr + '/*.yaml')[0]\n",
    "    config = edict(yaml.load(open(config_file, 'r'), Loader=yaml.FullLoader))\n",
    "        \n",
    "    vl = train_data['val_loss']\n",
    "    bvl = train_data['best_val_loss'][0]\n",
    "    arg_bvl = np.asarray(vl == bvl).nonzero()[0][0]\n",
    "\n",
    "    df = df.append({\"bvl\":bvl,\n",
    "                    \"hidden_dim\":config.model.hidden_dim,\n",
    "                    \"num_prop\":config.model.num_prop,\n",
    "                    \"aggregate_type\":config.model.aggregate_type,\n",
    "                    \"loss\":config.model.loss,\n",
    "                    \"lr\":config.train.lr,\n",
    "                    \"wd\":config.train.wd,\n",
    "                    \"vl\":vl,\n",
    "                    \"arg_bvl\":arg_bvl,\n",
    "                    \"v100_p\":p,\n",
    "                    \"v100_q\":q}, ignore_index=True)\n",
    "\n",
    "df = df.sort_values(['loss', 'bvl'], ascending=[True, True])\n",
    "df_KLqp, df_MSE, df_KLpq = df[:9], df[9:17], df[17:27]\n",
    "# df_KLpq, df_KLqp, df_MSE = df[:12], df[12:24], df[24:]\n",
    "# df_KLqp, df_KLpq, df_MSE = df[:12], df[12:24], df[24:]\n",
    "# df_MSE, df_KLqp, df_KLpq = df[:12], df[12:24], df[24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance on 20 validation graphs of |$\\mathcal{V}$| = 9 and 13 fixed structures\n",
    "#### Models with different hyperparameters, sorted by \"KL-pq\" Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KLpq.drop(['vl', 'arg_bvl', 'v100_p', 'v100_q'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_model = len(df_KLpq)\n",
    "f, axes = plt.subplots(nrows=int(np.ceil(num_model/6)), ncols=6, figsize=(25, 3*int(np.ceil(num_model/6))), dpi=100)\n",
    "for ii in range(num_model):\n",
    "    r = ii // 6\n",
    "    c = ii % 6\n",
    "    \n",
    "    vl = df_KLpq.iloc[ii]['vl']\n",
    "    bvl = df_KLpq.iloc[ii]['bvl']\n",
    "    arg_bvl = df_KLpq.iloc[ii]['arg_bvl']\n",
    "    \n",
    "    axes[r,c].plot(vl, markerfacecolor=\"None\", color='k', lw=0.3, label='val-loss')\n",
    "    axes[r,c].plot(arg_bvl, bvl, '^', ms=7, mfc=\"None\", color='r', label='best-val-loss')\n",
    "    axes[r,c].set_title(\"ID {} : {:.2e}\".format(df_KLpq.index[ii], bvl))\n",
    "    axes[r,c].set_ylim([-1e-3, 0.01])\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('fig0.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance on 10 test graphs of |$\\mathcal{V}$| = 9 and the same structure with training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_test = np.zeros((4,num_model,13)) + np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topology = ['barbell', 'binarytree', 'bipartite', 'circladder', 'complete', \n",
    "            'cycle', 'grid', 'ladder', 'lollipop', 'path', 'star', 'tripartite', 'wheel']\n",
    "loss_func = nn.KLDivLoss(reduction='batchmean')\n",
    "f, axes = plt.subplots(nrows=num_model, ncols=13, figsize=(40, 3*num_model), dpi=100)\n",
    "test_type = 'test_I'\n",
    "\n",
    "for r in range(num_model):\n",
    "    idx = df_KLpq.index[r]\n",
    "    config_file = glob(dirs[idx] + '/*.yaml')[0]\n",
    "    config = yaml.load(open(config_file, 'r'), Loader=yaml.FullLoader)\n",
    "    config['exp_dir'] = dirs[idx]\n",
    "    config['dataset']['data_path'] = '../data_christmas/'\n",
    "    config['dataset']['split'] = test_type\n",
    "    config['test']['test_model'] = dirs[idx] + '/model_snapshot_best.pth'\n",
    "    config['test']['batch_size'] = 1\n",
    "    cfg_path = dirs[idx] + '/config_test.yaml'\n",
    "    with open(cfg_path, 'w') as ymlfile:\n",
    "        yaml.dump(config, ymlfile, explicit_start=True)\n",
    "\n",
    "    ! python3 run_exp_local.py -c {cfg_path} -t\n",
    "    \n",
    "    test_files = glob(dirs[idx] + '/*' + test_type + '.csv')\n",
    "    q = pd.read_csv(test_files[0], sep='\\t', header=None).values.reshape(13,90,2)\n",
    "    p = pd.read_csv(test_files[1], sep='\\t', header=None).values.reshape(13,90,2)\n",
    "    \n",
    "    for c in range(len(topology)):\n",
    "        axes[r,c].plot([[0,0],[1,1]],'k:')\n",
    "        axes[r,c].plot(p[c][:,0], q[c][:,0], '.', markerfacecolor=\"None\", color='b')\n",
    "        axes[r,c].set_xlim([0, 1])\n",
    "        axes[r,c].set_ylim([0, 1])\n",
    "        axes[r,c].set_xticklabels([])\n",
    "        #axes[r,c].set_yticklabels([])\n",
    "        axes[r,c].axis('on')\n",
    "        \n",
    "        P = torch.Tensor(p[c])\n",
    "        Q = torch.Tensor(q[c])\n",
    "        \n",
    "        loss = loss_func(torch.log(Q), P).item()\n",
    "        Loss_test[0,r,c] = loss\n",
    "        if r == 0:\n",
    "            axes[r,c].set_title(topology[c]+\"\\n {:.2e}\".format(loss))\n",
    "        else:\n",
    "            axes[r,c].set_title(\"\\n {:.2e}\".format(loss))\n",
    "            \n",
    "        if c == 0:\n",
    "            axes[r,c].set_yticks([])\n",
    "            axes[r,c].set_ylabel(\"ID {}\".format(df_KLpq.index[r]))\n",
    "        else:\n",
    "            axes[r,c].set_yticklabels([])\n",
    "            \n",
    "# plt.show()\n",
    "plt.savefig('fig1.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance on 10 test graphs of |$\\mathcal{V}$| = 100 and the same structure with training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(nrows=num_model, ncols=13, figsize=(40, 3*num_model), dpi=100)\n",
    "\n",
    "for r in range(num_model):\n",
    "    p = df_KLpq.iloc[r]['v100_p']\n",
    "    q = df_KLpq.iloc[r]['v100_q']\n",
    "    for c in range(len(topology)):\n",
    "        if c == 8:\n",
    "            axes[r,c].plot([[0,0],[1,1]],'k:')\n",
    "            for ii in range(10):\n",
    "                axes[r,c].plot(p[c][100*ii : 100*ii+51,0], q[c][100*ii : 100*ii+51,0], '.', markerfacecolor=\"None\", color='b')\n",
    "                axes[r,c].plot(p[c][100*ii+51 : 100*(ii+1):,0], q[c][100*ii+51 : 100*(ii+1),0], '.', markerfacecolor=\"None\", color='r')\n",
    "            axes[r,c].set_xlim([0, 1])\n",
    "            axes[r,c].set_ylim([0, 1])\n",
    "            axes[r,c].set_xticklabels([])\n",
    "            #axes[r,c].set_yticklabels([])\n",
    "            axes[r,c].axis('on')\n",
    "\n",
    "            P = torch.Tensor(p[c])\n",
    "            Q = torch.Tensor(q[c])\n",
    "\n",
    "            loss = loss_func(torch.log(Q), P).item()\n",
    "            Loss_test[1,r,c] = loss\n",
    "            if r == 0:\n",
    "                axes[r,c].set_title(topology[c]+\"\\n {:.2e}\".format(loss))\n",
    "            else:\n",
    "                axes[r,c].set_title(\"\\n {:.2e}\".format(loss))\n",
    "\n",
    "            if c == 0:\n",
    "                axes[r,c].set_yticks([])\n",
    "                axes[r,c].set_ylabel(\"ID {}\".format(df_KLpq.index[r]))\n",
    "            else:\n",
    "                axes[r,c].set_yticklabels([])\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('fig2.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(nrows=num_model, ncols=13, figsize=(40, 3*num_model), dpi=100)\n",
    "\n",
    "for r in range(num_model):\n",
    "    p = df_KLpq.iloc[r]['v100_p']\n",
    "    q = df_KLpq.iloc[r]['v100_q']\n",
    "    for c in range(len(topology)):\n",
    "        axes[r,c].plot([[0,0],[1,1]],'k:')\n",
    "        axes[r,c].plot(p[c][:,0], q[c][:,0], '.', markerfacecolor=\"None\", color='b')\n",
    "        axes[r,c].set_xlim([0, 1])\n",
    "        axes[r,c].set_ylim([0, 1])\n",
    "        axes[r,c].set_xticklabels([])\n",
    "        #axes[r,c].set_yticklabels([])\n",
    "        axes[r,c].axis('on')\n",
    "        \n",
    "        P = torch.Tensor(p[c])\n",
    "        Q = torch.Tensor(q[c])\n",
    "        \n",
    "        loss = loss_func(torch.log(Q), P).item()\n",
    "        Loss_test[1,r,c] = loss\n",
    "        if r == 0:\n",
    "            axes[r,c].set_title(topology[c]+\"\\n {:.2e}\".format(loss))\n",
    "        else:\n",
    "            axes[r,c].set_title(\"\\n {:.2e}\".format(loss))\n",
    "            \n",
    "        if c == 0:\n",
    "            axes[r,c].set_yticks([])\n",
    "            axes[r,c].set_ylabel(\"ID {}\".format(df_KLpq.index[r]))\n",
    "        else:\n",
    "            axes[r,c].set_yticklabels([])\n",
    "            \n",
    "# plt.show()\n",
    "plt.savefig('fig2.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance on 10 test graphs of the \n",
    "### Same Size ( |$\\mathcal{V}$| = 9 ) & Same Degree Distribution but\n",
    "### Anisomorphic with training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree(G):\n",
    "    degree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n",
    "    degreeCount = collections.Counter(degree_sequence)\n",
    "    deg, cnt = zip(*degreeCount.items())\n",
    "    return degree_sequence, deg, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topology = ['barbell', 'binarytree', 'bipartite', 'circladder', 'complete', \n",
    "            'cycle', 'grid', 'ladder', 'lollipop', 'path', 'star', 'tripartite', 'wheel']\n",
    "ignorable = ['binarytree', 'complete', 'cycle', 'path', 'star', 'tripartite', 'wheel']\n",
    "\n",
    "f, axes = plt.subplots(nrows=10+num_model, ncols=13, figsize=(40, 3*(10+num_model)), dpi=100)\n",
    "test_type = 'test_III'\n",
    "\n",
    "for r in range(num_model):\n",
    "    idx = df_KLpq.index[r]\n",
    "    config_file = glob(dirs[idx] + '/*.yaml')[0]\n",
    "    config = yaml.load(open(config_file, 'r'), Loader=yaml.FullLoader)\n",
    "    config['exp_dir'] = dirs[idx]\n",
    "    config['dataset']['data_path'] = '../data_christmas/'\n",
    "    config['dataset']['split'] = test_type\n",
    "    config['test']['test_model'] = dirs[idx] + '/model_snapshot_best.pth'\n",
    "    config['test']['batch_size'] = 1\n",
    "    cfg_path = dirs[idx] + '/config_test.yaml'\n",
    "    with open(cfg_path, 'w') as ymlfile:\n",
    "        yaml.dump(config, ymlfile, explicit_start=True)\n",
    "\n",
    "    ! python3 run_exp_local.py -c {cfg_path} -t\n",
    "    \n",
    "    test_files = glob(dirs[idx] + '/*' + test_type + '.csv')\n",
    "    q = pd.read_csv(test_files[0], sep='\\t', header=None).values.reshape(13-len(ignorable),90,2)\n",
    "    p = pd.read_csv(test_files[1], sep='\\t', header=None).values.reshape(13-len(ignorable),90,2)\n",
    "    \n",
    "    itp = 0\n",
    "    for c, tp in enumerate(topology):\n",
    "        if tp not in ignorable:\n",
    "            if r == 0:\n",
    "                data_files = glob('../data_christmas/' + test_type +'/*_' + tp + '_*.p')\n",
    "                for idf, file in enumerate(data_files):\n",
    "                    train_data = pickle.load(open(file, 'rb'))\n",
    "                    \n",
    "                    nx.draw(train_data['G'], ax=axes[idf, c])\n",
    "                    _, dd, cc = degree(train_data['G'])\n",
    "                    if idf == 0:\n",
    "                        axes[idf, c].set_title(topology[c] + \"\\n d{}, c{}\".format(dd, cc))\n",
    "                    else:\n",
    "                        axes[idf, c].set_title(\"d{}, c{}\".format(dd, cc))\n",
    "                \n",
    "            axes[10+r,c].plot([[0,0],[1,1]],'k:')\n",
    "            axes[10+r,c].plot(p[itp][:,0], q[itp][:,0], '.', markerfacecolor=\"None\", color='b')\n",
    "            axes[10+r,c].set_xlim([0, 1])\n",
    "            axes[10+r,c].set_ylim([0, 1])\n",
    "            axes[10+r,c].set_xticks([])\n",
    "            axes[10+r,c].set_xticklabels([])\n",
    "            #axes[10+r,c].set_yticklabels([])\n",
    "            axes[10+r,c].axis('on')\n",
    "\n",
    "            P = torch.Tensor(p[itp])\n",
    "            Q = torch.Tensor(q[itp])\n",
    "            \n",
    "            loss = loss_func(torch.log(Q), P).item()\n",
    "            Loss_test[2,r,c] = loss\n",
    "            itp += 1\n",
    "\n",
    "#             if r == 0:\n",
    "#                 axes[10+r,c].set_title(topology[c]+\"\\n {:.2e}\".format(loss))\n",
    "#             else:\n",
    "#                 axes[10+r,c].set_title(\"\\n {:.2e}\".format(loss))\n",
    "            axes[10+r,c].set_title(\"\\n {:.2e}\".format(loss))\n",
    "\n",
    "        if c == 0:\n",
    "            axes[10+r,c].set_yticks([])\n",
    "            axes[10+r,c].set_ylabel(\"ID {}\".format(df_KLpq.index[r]))\n",
    "        else:\n",
    "            axes[r,c].set_xticks([])\n",
    "            axes[r,c].set_xticklabels([])\n",
    "            axes[r,c].set_yticks([])\n",
    "            axes[r,c].set_yticklabels([])\n",
    "            axes[10+r,c].set_xticks([])\n",
    "            axes[10+r,c].set_xticklabels([])\n",
    "            axes[10+r,c].set_yticks([])\n",
    "            axes[10+r,c].set_yticklabels([])\n",
    "            \n",
    "# plt.show()\n",
    "plt.savefig('fig3.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance on 10 test graphs of the \n",
    "### Same Size ( |$\\mathcal{V}$| = 9 ) & Same Unique Degrees but\n",
    "### Anisomorphic with training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology = ['barbell', 'binarytree', 'bipartite', 'circladder', 'complete', \n",
    "            'cycle', 'grid', 'ladder', 'lollipop', 'path', 'star', 'tripartite', 'wheel']\n",
    "ignorable = ['complete', 'cycle', 'path', 'star', 'tripartite', 'wheel']\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(nrows=10+num_model, ncols=13, figsize=(40, 3*(10+num_model)), dpi=100)\n",
    "test_type = 'test_IV'\n",
    "\n",
    "for r in range(num_model):\n",
    "    idx = df_KLpq.index[r]\n",
    "    config_file = glob(dirs[idx] + '/*.yaml')[0]\n",
    "    config = yaml.load(open(config_file, 'r'), Loader=yaml.FullLoader)\n",
    "    config['exp_dir'] = dirs[idx]\n",
    "    config['dataset']['data_path'] = '../data_christmas/'\n",
    "    config['dataset']['split'] = test_type\n",
    "    config['test']['test_model'] = dirs[idx] + '/model_snapshot_best.pth'\n",
    "    config['test']['batch_size'] = 1\n",
    "    cfg_path = dirs[idx] + '/config_test.yaml'\n",
    "    with open(cfg_path, 'w') as ymlfile:\n",
    "        yaml.dump(config, ymlfile, explicit_start=True)\n",
    "\n",
    "    ! python3 run_exp_local.py -c {cfg_path} -t\n",
    "    \n",
    "    test_files = glob(dirs[idx] + '/*' + test_type + '.csv')\n",
    "    q = pd.read_csv(test_files[0], sep='\\t', header=None).values.reshape(13-len(ignorable),90,2)\n",
    "    p = pd.read_csv(test_files[1], sep='\\t', header=None).values.reshape(13-len(ignorable),90,2)\n",
    "    \n",
    "    itp = 0\n",
    "    for c, tp in enumerate(topology):\n",
    "        if tp not in ignorable:\n",
    "            if r == 0:\n",
    "                data_files = glob('../data_christmas/' + test_type +'/*_' + tp + '_*.p')\n",
    "                for idf, file in enumerate(data_files):\n",
    "                    train_data = pickle.load(open(file, 'rb'))\n",
    "                    \n",
    "                    nx.draw(train_data['G'], ax=axes[idf, c])\n",
    "                    _, dd, cc = degree(train_data['G'])\n",
    "                    if idf == 0:\n",
    "                        axes[idf, c].set_title(topology[c] + \"\\n d{}, c{}\".format(dd, cc))\n",
    "                    else:\n",
    "                        axes[idf, c].set_title(\"d{}, c{}\".format(dd, cc))\n",
    "                \n",
    "            axes[10+r,c].plot([[0,0],[1,1]],'k:')\n",
    "            axes[10+r,c].plot(p[itp][:,0], q[itp][:,0], '.', markerfacecolor=\"None\", color='b')\n",
    "            axes[10+r,c].set_xlim([0, 1])\n",
    "            axes[10+r,c].set_ylim([0, 1])\n",
    "            axes[10+r,c].set_xticks([])\n",
    "            axes[10+r,c].set_xticklabels([])\n",
    "            #axes[10+r,c].set_yticklabels([])\n",
    "            axes[10+r,c].axis('on')\n",
    "\n",
    "            P = torch.Tensor(p[itp])\n",
    "            Q = torch.Tensor(q[itp])\n",
    "            loss = loss_func(torch.log(Q), P).item()\n",
    "            Loss_test[3,r,c] = loss\n",
    "            itp += 1\n",
    "\n",
    "#             if r == 0:\n",
    "#                 axes[10+r,c].set_title(topology[c]+\"\\n {:.2e}\".format(loss))\n",
    "#             else:\n",
    "#                 axes[10+r,c].set_title(\"\\n {:.2e}\".format(loss))\n",
    "            axes[10+r,c].set_title(\"\\n {:.2e}\".format(loss))\n",
    "\n",
    "        if c == 0:\n",
    "            axes[10+r,c].set_yticks([])\n",
    "            axes[10+r,c].set_ylabel(\"ID {}\".format(df_KLpq.index[r]))\n",
    "        else:\n",
    "            axes[r,c].set_xticks([])\n",
    "            axes[r,c].set_xticklabels([])\n",
    "            axes[r,c].set_yticks([])\n",
    "            axes[r,c].set_yticklabels([])\n",
    "            axes[10+r,c].set_xticks([])\n",
    "            axes[10+r,c].set_xticklabels([])\n",
    "            axes[10+r,c].set_yticks([])\n",
    "            axes[10+r,c].set_yticklabels([])\n",
    "            \n",
    "# plt.show()\n",
    "plt.savefig('fig4.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(nrows=4, ncols=3, figsize=(20, 20), dpi=150)\n",
    "for ii in range(num_model):\n",
    "    r = ii // 3\n",
    "    c = ii % 3\n",
    "    axes[r,c].plot(np.log10(Loss_test[:,ii,:]).T, 'o-')\n",
    "    if ii == 0:\n",
    "        axes[r,c].legend([\"|V|=009, structured\",\"|V|=100, structured\",\n",
    "                          \"|V|=009, random (same-degrees)\",\"|V|=009, random (unique-degrees)\"], \n",
    "                          bbox_to_anchor=(0.3, 1.2))\n",
    "    if r == 3:\n",
    "        axes[r,c].set_xticks(range(13))\n",
    "        axes[r,c].set_xticklabels(topology, rotation=45, fontsize=12)\n",
    "    else:\n",
    "        axes[r,c].set_xticklabels([])\n",
    "    axes[r,c].set_ylim([-6,0])\n",
    "    axes[r,c].grid('true')\n",
    "    axes[r,c].set_title(\"ID {} : Test Loss\".format(df_KLpq.index[ii]))\n",
    "    axes[r,c].set_ylabel('$\\log_{10}(loss)$')\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('fig5.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import networkx as nx\n",
    "from utils.topology import NetworkTopology\n",
    "\n",
    "def degree(G):\n",
    "    degree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n",
    "    degreeCount = collections.Counter(degree_sequence)\n",
    "    deg, cnt = zip(*degreeCount.items())\n",
    "    return degree_sequence, deg, cnt\n",
    "\n",
    "def graph_to_adjacency_matrix(G):\n",
    "    n = G.number_of_nodes()\n",
    "    W = np.zeros([n, n])\n",
    "    for i in range(n):\n",
    "        W[i, [j for j in G.neighbors(i)]] = 1\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(nrows=2, ncols=10, figsize=(40, 6), dpi=150)\n",
    "graph9c_list = []\n",
    "gfile = glob('*.g6')[0]\n",
    "with open(gfile, 'rb') as file:  \n",
    "    for ii, line in enumerate(file):\n",
    "#         print(line)\n",
    "        \n",
    "#         if ii == 10:\n",
    "#             break\n",
    "            \n",
    "        G = nx.from_graph6_bytes(line[:-1])\n",
    "        graph9c_list.append(G)\n",
    "#         W = graph_to_adjacency_matrix(G)\n",
    "#         nx.draw(G, ax=axes[0,ii])\n",
    "#         axes[1,ii].imshow(W)\n",
    "        \n",
    "with open('graph9c.p', 'wb') as f:\n",
    "    pickle.dump(graph9c_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph9c_list = pickle.load(open('graph9c.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph9c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(nrows=1, ncols=13, figsize=(40, 3), dpi=150)\n",
    "tp_list = ['barbell', 'binarytree', 'bipartite', 'circladder', 'complete', \n",
    "            'cycle', 'grid', 'ladder', 'lollipop', 'path', 'star', 'tripartite', 'wheel']\n",
    "tp_list = ['lollipop']\n",
    "\n",
    "\n",
    "ntp = NetworkTopology(num_nodes=9, seed=1234)\n",
    "for ii, tt in enumerate(tp_list):\n",
    "    G, _ = ntp.generate(topology=tt)\n",
    "    \n",
    "    if tt in ['bipartite', 'complete', 'tripartite']:\n",
    "        nx.draw_circular(G, with_labels=True, ax=axes[ii])\n",
    "    else:\n",
    "        nx.draw(G, with_labels=True, ax=axes[ii])\n",
    "        \n",
    "    #mcb = nx.minimum_cycle_basis(G)\n",
    "    #lc = np.unique([len(cy) for cy in mcb])\n",
    "    #clq = nx.node_clique_number(G)\n",
    "    #dm = nx.diameter(G)\n",
    "    ccl = nx.cycle_basis(G)\n",
    "    axes[ii].set_title(\"{}\".format(ccl))\n",
    "#     if tt == 'bipartite':\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw_circular(G0, with_labels=True)\n",
    "nx.draw(G0, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.minimum_cycle_basis(G0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.cycle_basis(G0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G0 = nx.complete_multipartite_graph(3,3,3)\n",
    "# G0 = nx.complete_bipartite_graph(4, 5)\n",
    "# G0 = nx.cycle_graph(9)\n",
    "# _, deg, count = degree(G0)\n",
    "# W = graph_to_adjacency_matrix(G0)\n",
    "\n",
    "# G0 = nx.grid_2d_graph(3,3)\n",
    "# seq, deg, count = degree(G0)\n",
    "\n",
    "# W = np.zeros([9,9])\n",
    "# nodes = [n for n in G0.nodes]\n",
    "# for i in range(9):\n",
    "#     for j in G0.neighbors(nodes[i]):\n",
    "#         W[i, 3 * j[0] + j[1]] = 1\n",
    "    \n",
    "# G = [G0]\n",
    "# f, axes = plt.subplots(nrows=2, ncols=10, figsize=(40, 6), dpi=200)\n",
    "# nx.draw(G0, ax=axes[0,0])\n",
    "# axes[0,0].set_title(\"{}, {}\".format(deg, count))\n",
    "# axes[1,0].imshow(W)\n",
    "    \n",
    "# cnt = 0\n",
    "# for i in range(1,100):\n",
    "#     legitimate = True\n",
    "#     try:\n",
    "#         seq = unique_deg_preserved_seq(deg, count)\n",
    "#         G_new = nx.random_degree_sequence_graph(seq)\n",
    "#         for j in range(len(G)):\n",
    "#             if nx.is_isomorphic(G[j],G_new) or not nx.is_connected(G_new):\n",
    "#                 legitimate = False\n",
    "#                 break\n",
    "#         if legitimate:\n",
    "#             G.append(G_new)\n",
    "#             cnt += 1\n",
    "\n",
    "#             nx.draw(G_new, ax=axes[0,cnt])\n",
    "#             _, dd, cc = degree(G_new)\n",
    "#             axes[0,cnt].set_title(\"{}, {}\".format(dd, cc))\n",
    "#             W = graph_to_adjacency_matrix(G_new)\n",
    "#             axes[1,cnt].imshow(W)\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     if cnt == 9:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
